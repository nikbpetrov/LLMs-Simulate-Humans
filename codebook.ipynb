{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general python packages\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# general data processing/analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import pingouin as pg # chronbach's alpha\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "\n",
    "# used for BBC data processing\n",
    "import pyreadstat\n",
    "import pycountry\n",
    "\n",
    "# used for API data collection\n",
    "import requests\n",
    "sys.path.append('shared')\n",
    "from api_request_parallel_processor import process_api_requests_from_file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all scales item info as df - used throughout during data processing\n",
    "all_scales_item_info_df = pd.DataFrame()\n",
    "for scale in [\"bfi\", \"panas\", \"bpaq\", \"sscs\"]:\n",
    "    with open(os.path.join(\"shared\", f\"{scale}_item_info.json\"), 'r') as f:\n",
    "        scale_item_info_df = pd.DataFrame(json.load(f)).transpose().reset_index().rename(columns={\"index\": \"item_index\"})\n",
    "    scale_item_info_df[\"scale\"] = scale.upper()\n",
    "    # scale_item_info_df[\"item_index\"] = scale_item_info_df[\"item_index\"].astype(str)\n",
    "\n",
    "    all_scales_item_info_df = pd.concat([all_scales_item_info_df, scale_item_info_df]).reset_index(drop=True)\n",
    "\n",
    "all_scales_item_info_df[\"item_index\"] = all_scales_item_info_df[\"item_index\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full BBC data is not shareable, so we only load the processed files that we need. The original data was held in a bbc_data folder, so every time the original data were used, you will see that check so you can see the code used to process the data. However, that code won't be run as this folder is not shared publicly.\n",
    "\n",
    "This pattern of checking for the `bbc_data` folder and loading only sharable files repeats throughout this codebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"bbc_data\")):\n",
    "    # we can only share the bbc_meta file - this shows all variables in the BBC dataset, as well as value labels etc\n",
    "    # for more info and methods, see https://ofajardo.github.io/pyreadstat_documentation/_build/html/index.html#metadata-object-description\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_meta.pickle\"), \"rb\") as f:\n",
    "        bbc_meta = pickle.load(f)\n",
    "else:\n",
    "    load_from_picklefile = True\n",
    "\n",
    "    if load_from_picklefile:\n",
    "        with open(os.path.join(\"data\", \"bbc_data\", \"raw_bbc_df, bbc_meta, bbc_df.pickle\"), \"rb\") as f:\n",
    "            raw_bbc_df, bbc_meta, bbc_df = pickle.load(f)\n",
    "    else:\n",
    "        raw_bbc_df, bbc_meta = pyreadstat.read_sav(os.path.join(\"data\", \"bbc_data\", \"raw_bbc_data.sav\"))\n",
    "\n",
    "        # a bit confusing here as we lightly process the raw bbc data, but this is needed for the later filtering/sampling\n",
    "        raw_bbc_df['uid'] = raw_bbc_df['uid'].str.strip()\n",
    "        # keep unique user id entries - only cases where all BFIs are non-NA and take the earliest entry\n",
    "        raw_bbc_df = raw_bbc_df.dropna(subset=[e for e in raw_bbc_df.columns if e.startswith('bfi_')]).sort_values(by=['uid', 'time_st']).drop_duplicates(subset='uid')\n",
    "\n",
    "        bbc_df = raw_bbc_df.copy()\n",
    "        bbc_df = bbc_df[[\"uid\"] + [e for e in bbc_df.columns if e.startswith(\"bfi_\")]].melt(id_vars='uid', var_name='item_index', value_name='numeric_response')\n",
    "        bbc_df[\"item_index\"] = bbc_df[\"item_index\"].apply(lambda x: x.split(\"_\")[1]).astype(int)\n",
    "        bbc_df = pd.merge(bbc_df, all_scales_item_info_df.query(\"scale=='BFI'\").drop(columns=['scale']), on=\"item_index\", how=\"left\")\n",
    "        # NB: We assume that scores are not to be reversed as per the syntax - reliability and scoring.sps ---\n",
    "        bbc_df['response_reversed'] = bbc_df['numeric_response']\n",
    "\n",
    "        # these were files used during development for faster loading\n",
    "        with open(os.path.join(\"data\", \"bbc_data\", \"raw_bbc_df, bbc_meta, bbc_df.pickle\"), \"wb\") as f:\n",
    "            pickle.dump([raw_bbc_df, bbc_meta, bbc_df], f)\n",
    "\n",
    "        # these are files that are shared\n",
    "        with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_meta.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(bbc_meta, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating silicon samples from BBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikolay Petrov\\AppData\\Local\\Temp\\ipykernel_19108\\496680385.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(min(len(x), n_samples // len(df['composite_key'].unique())), random_state=0)))\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"bbc_data\")):\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_silicon_samples_df.pickle\"), \"rb\") as f:\n",
    "        bbc_silicon_samples_df = pickle.load(f)\n",
    "else:\n",
    "    sub_bbc_df = raw_bbc_df[[\"uid\", \"age\", \"country\", \"ethnic\", \"m_schl\", \"f_schl\", \"n_sib\", \"sex\",\n",
    "            \"st_pub\", \"occ_sta\", \"occ_cat\", \"income\", \n",
    "            \"rstat_1\", \"chldrn\"]].copy()\n",
    "\n",
    "    sub_bbc_df['country_name'] = sub_bbc_df['country'].apply(lambda x: pycountry.countries.get(alpha_2=x).name if pycountry.countries.get(alpha_2=x) else np.nan)\n",
    "\n",
    "    sub_bbc_df = sub_bbc_df.query('(age>=18 and age<=99 and age.notna()) and '\n",
    "                '(ethnic in [1,2,3,4,5,6,8]) and '\n",
    "                '(country_name.notna()) and '\n",
    "                '(m_schl in [1,2,3,4,5,6]) and '\n",
    "                '(f_schl in [1,2,3,4,5,6]) and '\n",
    "                '(n_sib.notna()) and '\n",
    "                '(sex.notna()) and '\n",
    "                '(st_pub.notna()) and '\n",
    "                '(occ_sta.notna()) and '\n",
    "                '(occ_cat.notna() and occ_cat!=23) and '\n",
    "                '(income in [1,2,3,4,5,6,7]) and '\n",
    "                '(rstat_1 in [0,1]) and '\n",
    "                '(chldrn.notna())'\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # function code courtesy of chatGPT\n",
    "    # if you give a list of categories, it will do stratified sampling based on those categories\n",
    "    # an empty list will results in proportional sampling across all categories\n",
    "    def stratified_sampling(df, categories, n_samples):\n",
    "        # Create a composite key combining all categories\n",
    "        df['composite_key'] = df[categories].apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "        final_sample_composite = (df.groupby('composite_key', group_keys=False)\n",
    "                                    .apply(lambda x: x.sample(min(len(x), n_samples // len(df['composite_key'].unique())), random_state=0)))\n",
    "        # If the sample is smaller than required, randomly sample additional rows\n",
    "        if len(final_sample_composite) < n_samples:\n",
    "            additional_samples = df.drop(final_sample_composite.index).sample(n_samples - len(final_sample_composite), random_state=0)\n",
    "            final_sample_composite = pd.concat([final_sample_composite, additional_samples])\n",
    "\n",
    "        return final_sample_composite.drop(columns=['composite_key']).reset_index(drop=True)\n",
    "        \n",
    "    # random sampling, i.e. proportional... reproducible\n",
    "    bbc_silicon_samples_df = stratified_sampling(sub_bbc_df, [], 1000)\n",
    "\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_silicon_samples_df.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(bbc_silicon_samples_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the sentences to the `bbc_silicon_samples_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Originally, `country` should have been used but was inadvertently omitted when creating the personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>m_schl</th>\n",
       "      <th>f_schl</th>\n",
       "      <th>n_sib</th>\n",
       "      <th>sex</th>\n",
       "      <th>st_pub</th>\n",
       "      <th>occ_sta</th>\n",
       "      <th>occ_cat</th>\n",
       "      <th>income</th>\n",
       "      <th>rstat_1</th>\n",
       "      <th>chldrn</th>\n",
       "      <th>country_name</th>\n",
       "      <th>persona_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1df2ed9e02e998d7e3efa037a4926a7abaddb6e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>I am 38 years old.  My ethnic background is Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21f1b6f7c6ced9e3f4c805d3cccaee6de4a7c657</td>\n",
       "      <td>50.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>I am 50 years old.  My ethnic background is Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62fdeb795ca7af9f0bf0cbf8498e8501aabc612a</td>\n",
       "      <td>41.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>I am 41 years old.  My ethnic background is Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbc77cf36c46b0f79f3afd306748638c936033d3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>I am 26 years old.  My ethnic background is Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7d2c2587f29b5a7c543c424c7fc3216c0e0ec923</td>\n",
       "      <td>33.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>I am 33 years old.  My ethnic background is Wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        uid   age country  ethnic  m_schl  \\\n",
       "0  e1df2ed9e02e998d7e3efa037a4926a7abaddb6e  38.0      GB     8.0     1.0   \n",
       "1  21f1b6f7c6ced9e3f4c805d3cccaee6de4a7c657  50.0      GB     8.0     2.0   \n",
       "2  62fdeb795ca7af9f0bf0cbf8498e8501aabc612a  41.0      GB     8.0     4.0   \n",
       "3  fbc77cf36c46b0f79f3afd306748638c936033d3  26.0      GB     8.0     2.0   \n",
       "4  7d2c2587f29b5a7c543c424c7fc3216c0e0ec923  33.0      GB     8.0     5.0   \n",
       "\n",
       "   f_schl  n_sib  sex  st_pub  occ_sta  occ_cat  income  rstat_1  chldrn  \\\n",
       "0     1.0    1.0  1.0     1.0      3.0      8.0     6.0      1.0     2.0   \n",
       "1     1.0    2.0  1.0     1.0      3.0     19.0     4.0      1.0     3.0   \n",
       "2     3.0    1.0  1.0     1.0      3.0      8.0     7.0      1.0     1.0   \n",
       "3     2.0    0.0  0.0     1.0      3.0     17.0     6.0      1.0     0.0   \n",
       "4     5.0    1.0  1.0     1.0      3.0      4.0     7.0      1.0     0.0   \n",
       "\n",
       "     country_name                                persona_description  \n",
       "0  United Kingdom  I am 38 years old.  My ethnic background is Wh...  \n",
       "1  United Kingdom  I am 50 years old.  My ethnic background is Wh...  \n",
       "2  United Kingdom  I am 41 years old.  My ethnic background is Wh...  \n",
       "3  United Kingdom  I am 26 years old.  My ethnic background is Wh...  \n",
       "4  United Kingdom  I am 33 years old.  My ethnic background is Wh...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence(var_name, value):\n",
    "    if var_name==\"age\":\n",
    "        return f\"I am {int(value)} years old.\"\n",
    "    elif var_name==\"ethnic\":\n",
    "        return f\"My ethnic background is {bbc_meta.variable_value_labels['ethnic'][value].strip()}.\"\n",
    "    elif var_name==\"m_schl\" or var_name==\"f_schl\":\n",
    "        parent = \"mother\" if var_name==\"f_schl\" else \"father\"\n",
    "        if value==1:\n",
    "            sentence = f\"My {parent} did not complete GCSE / CSE / O-Levels.\"\n",
    "        elif value==2:\n",
    "            sentence = f\"The highest level of formal schooling my {parent} completed was GCSE / CSE / O-levels.\"\n",
    "        elif value==3:\n",
    "            sentence = f\"The highest level of formal schooling my {parent} completed was a post-16 vocational course.\"\n",
    "        elif value==4:\n",
    "            sentence = f\"The highest level of formal schooling my {parent} completed was A-Levels.\"\n",
    "        elif value==5:\n",
    "            sentence = f\"The highest level of formal schooling my {parent} completed was an Undergraduate degree.\"\n",
    "        elif value==6:\n",
    "            sentence = f\"The highest level of formal schooling my {parent} completed was a Postgraduate degree.\"\n",
    "        return sentence\n",
    "    elif var_name==\"n_sib\":\n",
    "        if value==0:\n",
    "            return f\"I do not have any siblings.\"\n",
    "        elif value>0 and value<6:\n",
    "            return f\"I have {int(value)} siblings.\"\n",
    "        elif value==6:\n",
    "            return f\"I have more than 5 siblings.\"\n",
    "    elif var_name==\"sex\":\n",
    "        return f\"I am {bbc_meta.variable_value_labels['sex'][value].strip()}.\"\n",
    "    elif var_name==\"st_pub\":\n",
    "        return f\"The majority of my education up to the age of 18 was in a {bbc_meta.variable_value_labels['st_pub'][value].strip()} school.\"\n",
    "    elif var_name==\"occ_sta\":\n",
    "        return f\"My occupational status can be defined as {bbc_meta.variable_value_labels['occ_sta'][value].strip()}.\"\n",
    "    elif var_name==\"occ_cat\":\n",
    "        return f\"I work in {bbc_meta.variable_value_labels['occ_cat'][value].strip()}.\"\n",
    "    elif var_name==\"income\":\n",
    "        sentence = f\"I earn {bbc_meta.variable_value_labels['income'][value].strip()}.\"\n",
    "        # replace £ before value with GBP afterwards\n",
    "        sentence = re.sub(r'£(\\d[\\d,.]*)', r'\\1GBP', sentence)\n",
    "        return sentence\n",
    "    elif var_name==\"rstat_1\":\n",
    "        if value==0:\n",
    "            return f\"I am currently not in an intimate relationship.\"\n",
    "        elif value==1:\n",
    "            return f\"I am currently in an intimate relationship.\"\n",
    "    elif var_name==\"chldrn\":\n",
    "        if value==0:\n",
    "            return f\"I do not have any children.\"\n",
    "        elif value>0 and value<6:\n",
    "            return f\"I have {int(value)} children.\"\n",
    "        elif value==6:\n",
    "            return f\"I have more than 5 children.\"\n",
    "    return \"\"\n",
    "\n",
    "def row_to_persona_description(row):\n",
    "    person_description = \"\"\n",
    "    for col_name, value in row.items():\n",
    "        person_description += get_sentence(col_name, value) + \" \"\n",
    "    return person_description.strip()\n",
    "\n",
    "bbc_silicon_samples_df['persona_description'] = bbc_silicon_samples_df.apply(row_to_persona_description, axis=1).reset_index(drop=True)\n",
    "bbc_silicon_samples_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the necesssary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items across all scales: 104\n",
      "Number of generic persona descriptions: 150\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('shared', 'scales_items.json'), 'r', encoding='utf-8') as f:\n",
    "    scales_items = json.load(f)\n",
    "    print(f\"Total number of items across all scales: {len(scales_items)}\")\n",
    "\n",
    "with open(os.path.join('shared', 'generic_persona_descriptions.json'), 'r', encoding='utf-8') as f:\n",
    "    generic_persona_descriptions = json.load(f)\n",
    "    print(f\"Number of generic persona descriptions: {len(generic_persona_descriptions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up parameters for the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_instruction = \"For the following task, respond in a way that matches this description:\"\n",
    "test_instruction = \"Evaluating the statement,\"\n",
    "\n",
    "item_postambles = {\n",
    "    \"BFI\": 'please indicate the extent to which you agree or disagree on a scale from 1 to 5 (where 1 = \"disagree strongly\", 2 = \"disagree a little\", 3 = \"neither agree nor disagree\", 4 = \"agree a little\", and 5 = \"agree strongly\"):',\n",
    "    \"PANAS\": 'indicate to what extent you agree on a scale from 1 to 5 (where 1 = \"very slightly or not at all agree\", 2 = \"agree a little\", 3 = \"agree moderately\", 4 = \"agree quite a bit\", and 5 = \"agree extremely\"):',\n",
    "    \"SSCS\": 'please decide to what extent this describes you on a scale from 1 to 5 (where 1 = \"strongly disagree\", 2 = \"disagree\", 3 = \"neither agree nor disagree\", 4 = \"agree\", 5 = \"strongly agree\"):',\n",
    "    \"BPAQ\": 'rate how characteristic this is of you on a scale from 1 to 5 (where 1 = \"extremely uncharacteristic of me\", 2 = \"uncharacteristic of me\", 3 = \"neither characteristic nor uncharacteristic of me\", 4 = \"characteristic of me\", and 5 = \"extremely characteristic of me\"):',\n",
    "    }\n",
    "items = []\n",
    "for item in scales_items:\n",
    "    new_item = item.copy()\n",
    "    new_item[\"item_postamble\"] = item_postambles[item[\"scale\"]]\n",
    "    items.append(new_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the requests for the generic persona descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are not meant to be rerun (but could be, outputs are deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    generic_gpt35_requests = []\n",
    "    generic_gpt4_requests = []\n",
    "\n",
    "    request_id = 0\n",
    "    for persona_description in generic_persona_descriptions:\n",
    "        for item in items:\n",
    "            prompt = f'{persona_instruction} \"{persona_description}\" {test_instruction} \"{item[\"item\"]}\", {item[\"item_postamble\"]}'\n",
    "            \n",
    "            generic_gpt35_requests.append({\n",
    "                \"model\": \"gpt-3.5-turbo-1106\", \n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": 0,\n",
    "                \"max_tokens\": 50,\n",
    "                \"metadata\": {\"persona_description\": persona_description, \"item\": item, \"request_id\": f\"{request_id}\"}\n",
    "            })\n",
    "\n",
    "            generic_gpt4_requests.append({\n",
    "                \"model\": \"gpt-4-1106-preview\", \n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": 0,\n",
    "                \"max_tokens\": 250,\n",
    "                \"metadata\": {\"persona_description\": persona_description, \"item\": item, \"request_id\": f\"{request_id}\"}\n",
    "            })\n",
    "\n",
    "            request_id += 1\n",
    "        \n",
    "    with open(os.path.join(\"data\", \"raw_data\", \"generic_gpt35_requests.jsonl\"), \"w\") as f:\n",
    "        for request in generic_gpt35_requests:\n",
    "            json_string = json.dumps(request)\n",
    "            f.write(json_string + \"\\n\")\n",
    "\n",
    "    with open(os.path.join(\"data\", \"raw_data\", \"generic_gpt4_requests.jsonl\"), \"w\") as f:\n",
    "        for request in generic_gpt4_requests:\n",
    "            json_string = json.dumps(request)\n",
    "            f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the requests for the silicon samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The BFI requests for silicon sampling GPT3.5 were created and run previously, on 23/12/2023. The other requests were run on 20/01/2024.\n",
    "\n",
    "The files (both the `requests` file and the `requests_results`) are merged manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    silicon_gpt35_requests = []\n",
    "    silicon_gpt4_requests = []\n",
    "\n",
    "    gpt35_request_id = 44000\n",
    "    gpt4_request_id = 0\n",
    "\n",
    "    for ind, row in bbc_silicon_samples_df.iterrows():\n",
    "        uid = row['uid']\n",
    "        persona_description = row['persona_description']\n",
    "        for item in items:\n",
    "            prompt = f'{persona_instruction} \"{persona_description}\" {test_instruction} \"{item[\"item\"]}\", {item[\"item_postamble\"]}'\n",
    "            \n",
    "            if item['scale'] != 'BFI':\n",
    "                silicon_gpt35_requests.append({\n",
    "                    \"model\": \"gpt-3.5-turbo-1106\", \n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    \"temperature\": 0,\n",
    "                    \"max_tokens\": 50,\n",
    "                    \"metadata\": {\"uid\": uid, \"item\": item, \"request_id\": f\"{gpt35_request_id}\"}\n",
    "                })\n",
    "                gpt35_request_id += 1\n",
    "            \n",
    "            silicon_gpt4_requests.append({\n",
    "                \"model\": \"gpt-4-1106-preview\", \n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": 0,\n",
    "                \"max_tokens\": 250,\n",
    "                \"metadata\": {\"uid\": uid, \"item\": item, \"request_id\": f\"{gpt4_request_id}\"}\n",
    "            })\n",
    "            gpt4_request_id += 1\n",
    "\n",
    "    with open(os.path.join(\"data\", \"raw_data\", \"silicon_gpt35_requests.jsonl\"), \"w\") as f:\n",
    "        for request in silicon_gpt35_requests:\n",
    "            json_string = json.dumps(request)\n",
    "            f.write(json_string + \"\\n\")\n",
    "        \n",
    "    with open(os.path.join(\"data\", \"raw_data\", \"silicon_gpt4_requests.jsonl\"), \"w\") as f:\n",
    "        for request in silicon_gpt4_requests:\n",
    "            json_string = json.dumps(request)\n",
    "            f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the silicon files in order to upload to Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the original `silicon_gpt35_requests.jsonl`, `silicon_gpt35_requests_results.jsonl`, `silicon_gpt4_requests.jsonl`, and `silicon_gpt4_requests_results.jsonl` is >100MB, so here we split them into 3 files. We merge them back later on during data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for filename in [\"silicon_gpt35_requests\", \"silicon_gpt35_requests_results\", \"silicon_gpt4_requests\", \"silicon_gpt4_requests_results\"]:\n",
    "        curr_file_all_requests = []\n",
    "        with open(os.path.join(\"data\", \"raw_data\", f\"{filename}.jsonl\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            for request in f:\n",
    "                curr_file_all_requests.append(json.loads(request.strip()))\n",
    "\n",
    "        num_requests = len(curr_file_all_requests)\n",
    "        num_files = 3\n",
    "        # Calculate the number of requests per file considering the remainder\n",
    "        num_requests_per_file = num_requests // num_files\n",
    "        remainder = num_requests % num_files\n",
    "\n",
    "        for i in range(num_files):\n",
    "            start_index = i * num_requests_per_file + min(i, remainder)\n",
    "            end_index = start_index + num_requests_per_file + (1 if i < remainder else 0)\n",
    "            \n",
    "            with open(os.path.join(\"data\", \"raw_data\", f\"{filename}_part{i}.jsonl\"), \"w\") as f:\n",
    "                for request in curr_file_all_requests[start_index:end_index]:\n",
    "                    f.write(json.dumps(request) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the API requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses parallel processing as per OpenAI's recommendation: https://github.com/openai/openai-cookbook/blob/main/examples/api_request_parallel_processor.py\n",
    "\n",
    "Note that the `api_request_parallel_processor.py` has been modified!\n",
    "\n",
    "Creating the requests from above replaces the contents of the entire requests file, while executing the requests only appends to the results file (`save_filepath`).\n",
    "\n",
    "In order to rerun, you will need to create a .env file in the root directory of the project with your OpenAI key:<br>OPENAI_API_KEY=< YOUR API KEY >\n",
    "\n",
    "Also, uncomment the last line to rerun; commented out for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'requests_filepath': os.path.join(\"data\", \"raw_data\", \"generic_gpt35_requests.jsonl\"),\n",
    "    'save_filepath': os.path.join(\"data\", \"raw_data\", \"generic_gpt35_requests_results.jsonl\"),\n",
    "\n",
    "    # 'requests_filepath': os.path.join(\"data\", \"raw_data\", \"generic_gpt4_requests.jsonl\"),\n",
    "    # 'save_filepath': os.path.join(\"data\", \"raw_data\", \"generic_gpt4_requests_results.jsonl\"),\n",
    "\n",
    "    # 'requests_filepath': os.path.join(\"data\", \"raw_data\", \"silicon_gpt35_requests.jsonl\"),\n",
    "    # 'save_filepath': os.path.join(\"data\", \"raw_data\", \"silicon_gpt35_requests_results.jsonl\"),\n",
    "\n",
    "    # 'requests_filepath': os.path.join(\"data\", \"raw_data\", \"silicon_gpt4_requests.jsonl\"),\n",
    "    # 'save_filepath': os.path.join(\"data\", \"raw_data\", \"silicon_gpt4_requests_results.jsonl\"),\n",
    "\n",
    "    'request_url': 'https://api.openai.com/v1/chat/completions',\n",
    "    'api_key': os.getenv(\"OPENAI_API_KEY\"),\n",
    "    'max_requests_per_minute': 1,\n",
    "    'max_tokens_per_minute': 500_000,\n",
    "    'token_encoding_name': 'cl100k_base',\n",
    "    'max_attempts': 1,\n",
    "    'logging_level': 30  # This corresponds to logging.INFO\n",
    "}\n",
    "\n",
    "# await process_api_requests_from_file(**args)  # Since this is an async function, use await"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useed to get the first digit from chatGPT's responses\n",
    "def get_first_digit(response):\n",
    "    for char in response:\n",
    "        if char.isdigit():\n",
    "            return int(char)\n",
    "    return None\n",
    "    \n",
    "# used to process the raw responses from the API into a dataframe\n",
    "def get_df_from_requests_results(requests_filepath, remove_out_of_bounds_responses=True):\n",
    "    print(f\"\\nProcessing: {os.path.split(requests_filepath)[1]}\")\n",
    "    \n",
    "    requests_results=[]\n",
    "    with open(requests_filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            requests_results.append(json.loads(line.strip()))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # transforming persona_descriptions to unique user ids for study 1\n",
    "    if \"generic\" in requests_filepath:\n",
    "        df['uid'] = [e[2]['persona_description'] for e in requests_results]\n",
    "        df['uid'] = df['uid'].astype('category')\n",
    "        df['uid'] = df['uid'].cat.codes\n",
    "    else:\n",
    "        df['uid'] = [e[2]['uid'] for e in requests_results]\n",
    "\n",
    "    df['request_id'] = [int(e[2]['request_id']) for e in requests_results]\n",
    "    df['scale'] = [e[2]['item']['scale'] for e in requests_results]\n",
    "    df['item_index'] = [e[2]['item']['index'] for e in requests_results]\n",
    "    df['raw_response'] = [e[1]['choices'][0]['message']['content'] for e in requests_results]\n",
    "    df['first_token_is_digit'] = df['raw_response'].apply(lambda x: x[0].isdigit())\n",
    "    df['finish_reason'] = [e[1]['choices'][0]['finish_reason'] for e in requests_results]\n",
    "    df['numeric_response'] = df['raw_response'].apply(get_first_digit)\n",
    "\n",
    "    out_of_bound_responses_df = df[(df['numeric_response'] < 1) | (df['numeric_response'] > 5)]\n",
    "    print(f\"----Number of responses outside of 1-5 range: {len(out_of_bound_responses_df)} ({np.round(len(out_of_bound_responses_df)/len(df)*100, 2)}%)\")\n",
    "    if remove_out_of_bounds_responses and len(out_of_bound_responses_df) > 0:\n",
    "        df.loc[(df['numeric_response'] < 1) | (df['numeric_response'] > 5), 'numeric_response'] = None\n",
    "        print(\"--------Responses outside of 1-5 range removed!\")\n",
    "\n",
    "    # add scale item info - reversed & dimension\n",
    "    df = pd.merge(df, all_scales_item_info_df, on=[\"scale\", \"item_index\"], how=\"left\")\n",
    "    df['response_reversed'] = np.where(df['reversed'], 6 - df['numeric_response'], df['numeric_response'])\n",
    "\n",
    "    df = df.sort_values('request_id').reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we did split the requests_results of silicon personas into 3, so here we put them back together before processing. For completeness sake, we also put together the requests, not just the requests_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in [\"silicon_gpt35_requests\", \"silicon_gpt35_requests_results\", \"silicon_gpt4_requests\", \"silicon_gpt4_requests_results\"]:\n",
    "    # we will check if the file exists first and delete it, as otherwise the writing may fail\n",
    "    if os.path.exists(os.path.join(\"data\", \"raw_data\", f\"{filename}.jsonl\")):\n",
    "        os.remove(os.path.join(\"data\", \"raw_data\", f\"{filename}.jsonl\"))\n",
    "\n",
    "    num_files = 3\n",
    "\n",
    "    curr_file_all_requests = []\n",
    "    for i in range(num_files):\n",
    "        with open(os.path.join(\"data\", \"raw_data\", f\"{filename}_part{i}.jsonl\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            for request in f:\n",
    "                curr_file_all_requests.append(json.loads(request))\n",
    "    \n",
    "    with open(os.path.join(\"data\", \"raw_data\", f\"{filename}.jsonl\"), \"w\") as f:\n",
    "        for request in curr_file_all_requests:\n",
    "            f.write(json.dumps(request) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: generic_gpt35_requests_results.jsonl\n",
      "----Number of responses outside of 1-5 range: 0 (0.0%)\n",
      "\n",
      "Processing: generic_gpt4_requests_results.jsonl\n",
      "----Number of responses outside of 1-5 range: 86 (0.55%)\n",
      "--------Responses outside of 1-5 range removed!\n",
      "\n",
      "Processing: silicon_gpt35_requests_results.jsonl\n",
      "----Number of responses outside of 1-5 range: 0 (0.0%)\n",
      "\n",
      "Processing: silicon_gpt4_requests_results.jsonl\n",
      "----Number of responses outside of 1-5 range: 39 (0.04%)\n",
      "--------Responses outside of 1-5 range removed!\n"
     ]
    }
   ],
   "source": [
    "generic_gpt35_df = get_df_from_requests_results(os.path.join(\"data\", \"raw_data\", \"generic_gpt35_requests_results.jsonl\"))\n",
    "generic_gpt4_df = get_df_from_requests_results(os.path.join(\"data\", \"raw_data\", \"generic_gpt4_requests_results.jsonl\"))\n",
    "silicon_gpt35_df = get_df_from_requests_results(os.path.join(\"data\", \"raw_data\", \"silicon_gpt35_requests_results.jsonl\"))\n",
    "silicon_gpt4_df = get_df_from_requests_results(os.path.join(\"data\", \"raw_data\", \"silicon_gpt4_requests_results.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary scores dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"bbc_data\")):\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_summary_scores_df.pickle\"), \"rb\") as f:\n",
    "        bbc_summary_scores_df = pickle.load(f)\n",
    "else:\n",
    "    bbc_summary_scores_df = bbc_df.groupby(['uid', 'dimension'])['response_reversed'].mean().reset_index()\n",
    "\n",
    "    # we only save the summary scores of the 1000 silicon personas\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_summary_scores_df.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(bbc_summary_scores_df[bbc_summary_scores_df['uid'].isin(bbc_silicon_samples_df['uid'])], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_gpt35_summary_scores_df = generic_gpt35_df.groupby(['uid', 'scale', 'dimension'])['response_reversed'].mean().reset_index()\n",
    "generic_gpt4_summary_scores_df = generic_gpt4_df.groupby(['uid', 'scale', 'dimension'])['response_reversed'].mean().reset_index()\n",
    "silicon_gpt35_summary_scores_df = silicon_gpt35_df.groupby(['uid', 'scale', 'dimension'])['response_reversed'].mean().reset_index()\n",
    "silicon_gpt4_summary_scores_df = silicon_gpt4_df.groupby(['uid', 'scale', 'dimension'])['response_reversed'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal consistency - Cronbach's alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cronbach_alpha_df(df):\n",
    "    res = []\n",
    "    for scale in df['scale'].unique():\n",
    "        scale_sub_df = df[df['scale']==scale]\n",
    "        for dimension in scale_sub_df['dimension'].unique():\n",
    "            dimension_sub_df = scale_sub_df[scale_sub_df['dimension'] == dimension].reset_index(drop=False)\n",
    "            alpha = pg.cronbach_alpha(data=dimension_sub_df, items=\"item_index\", scores=\"response_reversed\", subject=\"uid\")\n",
    "            res.append({\n",
    "                \"scale\": scale,\n",
    "                \"dimension\": dimension,\n",
    "                \"alpha\": alpha[0]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>dimension</th>\n",
       "      <th>generic_gpt35_alpha</th>\n",
       "      <th>generic_gpt4_alpha</th>\n",
       "      <th>silicon_gpt35_alpha</th>\n",
       "      <th>silicon_gpt4_alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFI</td>\n",
       "      <td>Extraversion</td>\n",
       "      <td>0.582327</td>\n",
       "      <td>0.908532</td>\n",
       "      <td>0.550951</td>\n",
       "      <td>0.694504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFI</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.840415</td>\n",
       "      <td>0.537476</td>\n",
       "      <td>0.716157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFI</td>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>0.798723</td>\n",
       "      <td>0.873373</td>\n",
       "      <td>0.698126</td>\n",
       "      <td>0.837486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFI</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>0.722777</td>\n",
       "      <td>0.754785</td>\n",
       "      <td>0.530820</td>\n",
       "      <td>0.236343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFI</td>\n",
       "      <td>Openness</td>\n",
       "      <td>0.748060</td>\n",
       "      <td>0.891988</td>\n",
       "      <td>0.482531</td>\n",
       "      <td>0.759349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PANAS</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.949114</td>\n",
       "      <td>0.900143</td>\n",
       "      <td>0.794565</td>\n",
       "      <td>0.772256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PANAS</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.902645</td>\n",
       "      <td>0.860867</td>\n",
       "      <td>0.795136</td>\n",
       "      <td>0.595437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BPAQ</td>\n",
       "      <td>Physical</td>\n",
       "      <td>0.800601</td>\n",
       "      <td>0.880271</td>\n",
       "      <td>0.367608</td>\n",
       "      <td>0.428287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BPAQ</td>\n",
       "      <td>Verbal</td>\n",
       "      <td>0.625797</td>\n",
       "      <td>0.696505</td>\n",
       "      <td>0.332181</td>\n",
       "      <td>0.211077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BPAQ</td>\n",
       "      <td>Anger</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>0.862313</td>\n",
       "      <td>0.418108</td>\n",
       "      <td>0.544393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BPAQ</td>\n",
       "      <td>Hostility</td>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.855075</td>\n",
       "      <td>0.626262</td>\n",
       "      <td>0.608175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SSCS</td>\n",
       "      <td>Personal Identity</td>\n",
       "      <td>0.898337</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.457283</td>\n",
       "      <td>0.523022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SSCS</td>\n",
       "      <td>Self-efficacy</td>\n",
       "      <td>0.887736</td>\n",
       "      <td>0.799440</td>\n",
       "      <td>0.121259</td>\n",
       "      <td>0.551845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    scale          dimension  generic_gpt35_alpha  generic_gpt4_alpha  \\\n",
       "0     BFI       Extraversion             0.582327            0.908532   \n",
       "1     BFI      Agreeableness             0.852248            0.840415   \n",
       "2     BFI  Conscientiousness             0.798723            0.873373   \n",
       "3     BFI        Neuroticism             0.722777            0.754785   \n",
       "4     BFI           Openness             0.748060            0.891988   \n",
       "5   PANAS           Positive             0.949114            0.900143   \n",
       "6   PANAS           Negative             0.902645            0.860867   \n",
       "7    BPAQ           Physical             0.800601            0.880271   \n",
       "8    BPAQ             Verbal             0.625797            0.696505   \n",
       "9    BPAQ              Anger             0.813510            0.862313   \n",
       "10   BPAQ          Hostility             0.734315            0.855075   \n",
       "11   SSCS  Personal Identity             0.898337            0.876904   \n",
       "12   SSCS      Self-efficacy             0.887736            0.799440   \n",
       "\n",
       "    silicon_gpt35_alpha  silicon_gpt4_alpha  \n",
       "0              0.550951            0.694504  \n",
       "1              0.537476            0.716157  \n",
       "2              0.698126            0.837486  \n",
       "3              0.530820            0.236343  \n",
       "4              0.482531            0.759349  \n",
       "5              0.794565            0.772256  \n",
       "6              0.795136            0.595437  \n",
       "7              0.367608            0.428287  \n",
       "8              0.332181            0.211077  \n",
       "9              0.418108            0.544393  \n",
       "10             0.626262            0.608175  \n",
       "11             0.457283            0.523022  \n",
       "12             0.121259            0.551845  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_gpt35_cronbach_alpha_df = get_cronbach_alpha_df(generic_gpt35_df)\n",
    "generic_gpt4_cronbach_alpha_df = get_cronbach_alpha_df(generic_gpt4_df)\n",
    "silicon_gpt35_cronbach_alpha_df = get_cronbach_alpha_df(silicon_gpt35_df)\n",
    "silicon_gpt4_cronbach_alpha_df = get_cronbach_alpha_df(silicon_gpt4_df)\n",
    "\n",
    "tmp = [\n",
    "    generic_gpt35_cronbach_alpha_df.rename(columns={'alpha': 'generic_gpt35_alpha'}),\n",
    "    generic_gpt4_cronbach_alpha_df.rename(columns={'alpha': 'generic_gpt4_alpha'}),\n",
    "    silicon_gpt35_cronbach_alpha_df.rename(columns={'alpha': 'silicon_gpt35_alpha'}),\n",
    "    silicon_gpt4_cronbach_alpha_df.rename(columns={'alpha': 'silicon_gpt4_alpha'})\n",
    "]\n",
    "combined_cronbach_alpha_df = reduce(lambda left, right: pd.merge(left, right, on=['scale', 'dimension'], how='left'), tmp)\n",
    "combined_cronbach_alpha_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cronbach_alpha_df.to_csv(os.path.join(\"data\", \"data_for_R\", \"combined_cronbach_alpha_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterion validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_scores_df_wide(summary_scores_df):\n",
    "    summary_scores_df_wide = summary_scores_df.copy()\n",
    "    # this if would only apply to bbc anyways\n",
    "    if 'scale' not in summary_scores_df_wide.columns:\n",
    "        summary_scores_df_wide['scale'] = 'BFI'\n",
    "    summary_scores_df_wide['scale'] = summary_scores_df_wide['scale'] + '_' + summary_scores_df_wide['dimension']\n",
    "    summary_scores_df_wide = summary_scores_df_wide.pivot(index='uid', columns='scale', values='response_reversed').reset_index()\n",
    "    return summary_scores_df_wide\n",
    "\n",
    "def get_all_corrs_df(summary_scores_df):\n",
    "    summary_scores_df_wide = get_summary_scores_df_wide(summary_scores_df)\n",
    "    all_corrs_df = summary_scores_df_wide.drop(columns=['uid']).corr()\n",
    "    return all_corrs_df\n",
    "\n",
    "def get_validity_corr_df(summary_scores_df):\n",
    "    all_corrs_df = get_all_corrs_df(summary_scores_df)\n",
    "\n",
    "    corrs = [\n",
    "        {\"var1\": \"BFI_Extraversion\", \"var2\": \"PANAS_Positive\"},\n",
    "        {\"var1\": \"BFI_Extraversion\", \"var2\": \"PANAS_Negative\"},\n",
    "        {\"var1\": \"BFI_Agreeableness\", \"var2\": \"BPAQ_Physical\"},\n",
    "        {\"var1\": \"BFI_Agreeableness\", \"var2\": \"BPAQ_Verbal\"},\n",
    "        {\"var1\": \"BFI_Agreeableness\", \"var2\": \"BPAQ_Anger\"},\n",
    "        {\"var1\": \"BFI_Agreeableness\", \"var2\": \"BPAQ_Hostility\"},\n",
    "        {\"var1\": \"BFI_Neuroticism\", \"var2\": \"PANAS_Positive\"},\n",
    "        {\"var1\": \"BFI_Neuroticism\", \"var2\": \"PANAS_Negative\"},\n",
    "        {\"var1\": \"BFI_Openness\", \"var2\": \"SSCS_Self-efficacy\"},\n",
    "        {\"var1\": \"BFI_Openness\", \"var2\": \"SSCS_Personal Identity\"},\n",
    "    ]\n",
    "    corrs_res = []\n",
    "    for e in corrs:\n",
    "        new_e = e.copy()\n",
    "        new_e[\"r\"] = all_corrs_df.loc[e[\"var1\"], e[\"var2\"]]\n",
    "        corrs_res.append(new_e)\n",
    "\n",
    "    return pd.DataFrame(corrs_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>generic_gpt35_r</th>\n",
       "      <th>generic_gpt4_r</th>\n",
       "      <th>silicon_gpt35_r</th>\n",
       "      <th>silicon_gpt4_r</th>\n",
       "      <th>serapiogarcia_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFI_Extraversion</td>\n",
       "      <td>PANAS_Positive</td>\n",
       "      <td>0.549538</td>\n",
       "      <td>0.639075</td>\n",
       "      <td>0.391287</td>\n",
       "      <td>0.659101</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFI_Extraversion</td>\n",
       "      <td>PANAS_Negative</td>\n",
       "      <td>-0.224826</td>\n",
       "      <td>-0.251039</td>\n",
       "      <td>-0.061914</td>\n",
       "      <td>-0.432405</td>\n",
       "      <td>-0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFI_Agreeableness</td>\n",
       "      <td>BPAQ_Physical</td>\n",
       "      <td>-0.422217</td>\n",
       "      <td>-0.623247</td>\n",
       "      <td>-0.311311</td>\n",
       "      <td>-0.463211</td>\n",
       "      <td>-0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFI_Agreeableness</td>\n",
       "      <td>BPAQ_Verbal</td>\n",
       "      <td>-0.391460</td>\n",
       "      <td>-0.595906</td>\n",
       "      <td>-0.355661</td>\n",
       "      <td>-0.303203</td>\n",
       "      <td>-0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFI_Agreeableness</td>\n",
       "      <td>BPAQ_Anger</td>\n",
       "      <td>-0.620775</td>\n",
       "      <td>-0.653593</td>\n",
       "      <td>-0.085949</td>\n",
       "      <td>-0.262910</td>\n",
       "      <td>-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BFI_Agreeableness</td>\n",
       "      <td>BPAQ_Hostility</td>\n",
       "      <td>-0.374475</td>\n",
       "      <td>-0.641641</td>\n",
       "      <td>-0.040137</td>\n",
       "      <td>-0.343323</td>\n",
       "      <td>-0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFI_Neuroticism</td>\n",
       "      <td>PANAS_Positive</td>\n",
       "      <td>-0.609162</td>\n",
       "      <td>-0.581027</td>\n",
       "      <td>-0.405434</td>\n",
       "      <td>-0.351222</td>\n",
       "      <td>-0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BFI_Neuroticism</td>\n",
       "      <td>PANAS_Negative</td>\n",
       "      <td>0.447258</td>\n",
       "      <td>0.596179</td>\n",
       "      <td>0.576591</td>\n",
       "      <td>0.352590</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BFI_Openness</td>\n",
       "      <td>SSCS_Self-efficacy</td>\n",
       "      <td>0.602939</td>\n",
       "      <td>0.631863</td>\n",
       "      <td>0.186649</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BFI_Openness</td>\n",
       "      <td>SSCS_Personal Identity</td>\n",
       "      <td>0.675821</td>\n",
       "      <td>0.816544</td>\n",
       "      <td>0.292986</td>\n",
       "      <td>0.595221</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                var1                    var2  generic_gpt35_r  generic_gpt4_r  \\\n",
       "0   BFI_Extraversion          PANAS_Positive         0.549538        0.639075   \n",
       "1   BFI_Extraversion          PANAS_Negative        -0.224826       -0.251039   \n",
       "2  BFI_Agreeableness           BPAQ_Physical        -0.422217       -0.623247   \n",
       "3  BFI_Agreeableness             BPAQ_Verbal        -0.391460       -0.595906   \n",
       "4  BFI_Agreeableness              BPAQ_Anger        -0.620775       -0.653593   \n",
       "5  BFI_Agreeableness          BPAQ_Hostility        -0.374475       -0.641641   \n",
       "6    BFI_Neuroticism          PANAS_Positive        -0.609162       -0.581027   \n",
       "7    BFI_Neuroticism          PANAS_Negative         0.447258        0.596179   \n",
       "8       BFI_Openness      SSCS_Self-efficacy         0.602939        0.631863   \n",
       "9       BFI_Openness  SSCS_Personal Identity         0.675821        0.816544   \n",
       "\n",
       "   silicon_gpt35_r  silicon_gpt4_r  serapiogarcia_r  \n",
       "0         0.391287        0.659101             0.83  \n",
       "1        -0.061914       -0.432405            -0.59  \n",
       "2        -0.311311       -0.463211            -0.88  \n",
       "3        -0.355661       -0.303203            -0.72  \n",
       "4        -0.085949       -0.262910            -0.86  \n",
       "5        -0.040137       -0.343323            -0.73  \n",
       "6        -0.405434       -0.351222            -0.78  \n",
       "7         0.576591        0.352590             0.91  \n",
       "8         0.186649        0.688984             0.74  \n",
       "9         0.292986        0.595221             0.84  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_gpt35_validity_df = get_validity_corr_df(generic_gpt35_summary_scores_df)\n",
    "generic_gpt4_validity_df = get_validity_corr_df(generic_gpt4_summary_scores_df)\n",
    "silicon_gpt35_validity_df = get_validity_corr_df(silicon_gpt35_summary_scores_df)\n",
    "silicon_gpt4_validity_df = get_validity_corr_df(silicon_gpt4_summary_scores_df)\n",
    "\n",
    "tmp = [\n",
    "    generic_gpt35_validity_df.rename(columns={'r': 'generic_gpt35_r'}),\n",
    "    generic_gpt4_validity_df.rename(columns={'r': 'generic_gpt4_r'}),\n",
    "    silicon_gpt35_validity_df.rename(columns={'r': 'silicon_gpt35_r'}),\n",
    "    silicon_gpt4_validity_df.rename(columns={'r': 'silicon_gpt4_r'})\n",
    "]\n",
    "combined_validity_df = reduce(lambda left, right: pd.merge(left, right, on=['var1', 'var2'], how='left'), tmp)\n",
    "\n",
    "serapiogarcia_validity_corrs = pd.DataFrame([\n",
    "    {'var1': 'BFI_Extraversion', 'var2': 'PANAS_Positive', 'serapiogarcia_r': 0.83},\n",
    "    {'var1': 'BFI_Extraversion', 'var2': 'PANAS_Negative', 'serapiogarcia_r': -0.59},\n",
    "    {'var1': 'BFI_Agreeableness', 'var2': 'BPAQ_Physical', 'serapiogarcia_r': -0.88},\n",
    "    {'var1': 'BFI_Agreeableness', 'var2': 'BPAQ_Verbal', 'serapiogarcia_r': -0.72},\n",
    "    {'var1': 'BFI_Agreeableness', 'var2': 'BPAQ_Anger', 'serapiogarcia_r': -0.86},\n",
    "    {'var1': 'BFI_Agreeableness', 'var2': 'BPAQ_Hostility', 'serapiogarcia_r': -0.73},\n",
    "    {'var1': 'BFI_Neuroticism', 'var2': 'PANAS_Positive', 'serapiogarcia_r': -0.78},\n",
    "    {'var1': 'BFI_Neuroticism', 'var2': 'PANAS_Negative', 'serapiogarcia_r': 0.91},\n",
    "    {'var1': 'BFI_Openness', 'var2': 'SSCS_Self-efficacy', 'serapiogarcia_r': 0.74},\n",
    "    {'var1': 'BFI_Openness', 'var2': 'SSCS_Personal Identity', 'serapiogarcia_r': 0.84},\n",
    "])\n",
    "\n",
    "combined_validity_df = pd.merge(combined_validity_df, serapiogarcia_validity_corrs, on=['var1', 'var2'], how='left')\n",
    "combined_validity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_validity_df.to_csv(os.path.join(\"data\", \"data_for_R\", \"combined_validity_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFI Intercorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intercorrs_df(summary_scores_df):\n",
    "    all_corrs_df = get_all_corrs_df(summary_scores_df)\n",
    "\n",
    "    corrs = [{'var1': pair[0], 'var2': pair[1]} for pair in combinations([e for e in all_corrs_df.columns if e.startswith(\"BFI_\")], 2)]\n",
    "    \n",
    "    corrs_res = []\n",
    "    for e in corrs:\n",
    "        new_e = e.copy()\n",
    "        new_e[\"r\"] = all_corrs_df.loc[e[\"var1\"], e[\"var2\"]]\n",
    "        corrs_res.append(new_e)\n",
    "\n",
    "    # remove the \"BFI_\" prefix\n",
    "    intercorrs_df = pd.DataFrame(corrs_res)\n",
    "    intercorrs_df['var1'] = intercorrs_df['var1'].apply(lambda x: x[4:])\n",
    "    intercorrs_df['var2'] = intercorrs_df['var2'].apply(lambda x: x[4:])\n",
    "    return intercorrs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"bbc_data\")):\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_intercorrs_df.pickle\"), \"rb\") as f:\n",
    "        bbc_intercorrs_df = pickle.load(f)\n",
    "else:\n",
    "    bbc_intercorrs_df = get_intercorrs_df(bbc_summary_scores_df)\n",
    "\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_intercorrs_df.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(bbc_intercorrs_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>bbc_r</th>\n",
       "      <th>generic_gpt35_r</th>\n",
       "      <th>generic_gpt4_r</th>\n",
       "      <th>silicon_gpt35_r</th>\n",
       "      <th>silicon_gpt4_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>0.249485</td>\n",
       "      <td>0.723276</td>\n",
       "      <td>0.561472</td>\n",
       "      <td>0.515692</td>\n",
       "      <td>0.444196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Extraversion</td>\n",
       "      <td>0.133033</td>\n",
       "      <td>0.290510</td>\n",
       "      <td>0.338529</td>\n",
       "      <td>-0.029134</td>\n",
       "      <td>0.240552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>-0.294152</td>\n",
       "      <td>-0.660254</td>\n",
       "      <td>-0.392606</td>\n",
       "      <td>-0.228921</td>\n",
       "      <td>-0.073698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Openness</td>\n",
       "      <td>0.042664</td>\n",
       "      <td>0.328049</td>\n",
       "      <td>0.291930</td>\n",
       "      <td>-0.076287</td>\n",
       "      <td>0.215494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Extraversion</td>\n",
       "      <td>0.109946</td>\n",
       "      <td>0.421112</td>\n",
       "      <td>0.398048</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>0.475580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>-0.209726</td>\n",
       "      <td>-0.671202</td>\n",
       "      <td>-0.486946</td>\n",
       "      <td>-0.496567</td>\n",
       "      <td>-0.331981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Openness</td>\n",
       "      <td>-0.046006</td>\n",
       "      <td>0.394694</td>\n",
       "      <td>0.389919</td>\n",
       "      <td>0.080015</td>\n",
       "      <td>0.287101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>-0.334979</td>\n",
       "      <td>-0.370567</td>\n",
       "      <td>-0.467797</td>\n",
       "      <td>-0.269278</td>\n",
       "      <td>-0.379081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>Openness</td>\n",
       "      <td>0.194667</td>\n",
       "      <td>0.375182</td>\n",
       "      <td>0.232971</td>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.504078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>Openness</td>\n",
       "      <td>-0.074902</td>\n",
       "      <td>-0.333999</td>\n",
       "      <td>-0.114686</td>\n",
       "      <td>-0.186933</td>\n",
       "      <td>-0.197465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                var1               var2     bbc_r  generic_gpt35_r  \\\n",
       "0      Agreeableness  Conscientiousness  0.249485         0.723276   \n",
       "1      Agreeableness       Extraversion  0.133033         0.290510   \n",
       "2      Agreeableness        Neuroticism -0.294152        -0.660254   \n",
       "3      Agreeableness           Openness  0.042664         0.328049   \n",
       "4  Conscientiousness       Extraversion  0.109946         0.421112   \n",
       "5  Conscientiousness        Neuroticism -0.209726        -0.671202   \n",
       "6  Conscientiousness           Openness -0.046006         0.394694   \n",
       "7       Extraversion        Neuroticism -0.334979        -0.370567   \n",
       "8       Extraversion           Openness  0.194667         0.375182   \n",
       "9        Neuroticism           Openness -0.074902        -0.333999   \n",
       "\n",
       "   generic_gpt4_r  silicon_gpt35_r  silicon_gpt4_r  \n",
       "0        0.561472         0.515692        0.444196  \n",
       "1        0.338529        -0.029134        0.240552  \n",
       "2       -0.392606        -0.228921       -0.073698  \n",
       "3        0.291930        -0.076287        0.215494  \n",
       "4        0.398048         0.099804        0.475580  \n",
       "5       -0.486946        -0.496567       -0.331981  \n",
       "6        0.389919         0.080015        0.287101  \n",
       "7       -0.467797        -0.269278       -0.379081  \n",
       "8        0.232971         0.478022        0.504078  \n",
       "9       -0.114686        -0.186933       -0.197465  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_gpt35_intercorrs_df = get_intercorrs_df(generic_gpt35_summary_scores_df)\n",
    "generic_gpt4_intercorrs_df = get_intercorrs_df(generic_gpt4_summary_scores_df)\n",
    "silicon_gpt35_intercorrs_df = get_intercorrs_df(silicon_gpt35_summary_scores_df)\n",
    "silicon_gpt4_intercorrs_df = get_intercorrs_df(silicon_gpt4_summary_scores_df)\n",
    "\n",
    "tmp = [\n",
    "    bbc_intercorrs_df.rename(columns={'r': 'bbc_r'}),\n",
    "    generic_gpt35_intercorrs_df.rename(columns={'r': 'generic_gpt35_r'}),\n",
    "    generic_gpt4_intercorrs_df.rename(columns={'r': 'generic_gpt4_r'}),\n",
    "    silicon_gpt35_intercorrs_df.rename(columns={'r': 'silicon_gpt35_r'}),\n",
    "    silicon_gpt4_intercorrs_df.rename(columns={'r': 'silicon_gpt4_r'})\n",
    "]\n",
    "combined_intercorrs_df = reduce(lambda left, right: pd.merge(left, right, on=['var1', 'var2'], how='left'), tmp)\n",
    "combined_intercorrs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data export for R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R will require a slightly different format for the plotting, so we will process this here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>model</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>bbc</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>bbc</td>\n",
       "      <td>0.249485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Extraversion</td>\n",
       "      <td>bbc</td>\n",
       "      <td>0.133033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>bbc</td>\n",
       "      <td>-0.294152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>Openness</td>\n",
       "      <td>bbc</td>\n",
       "      <td>0.042664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            var1               var2 model         r\n",
       "0  Agreeableness      Agreeableness   bbc      <NA>\n",
       "1  Agreeableness  Conscientiousness   bbc  0.249485\n",
       "2  Agreeableness       Extraversion   bbc  0.133033\n",
       "3  Agreeableness        Neuroticism   bbc -0.294152\n",
       "4  Agreeableness           Openness   bbc  0.042664"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = pd.unique(combined_intercorrs_df[['var1', 'var2']].values.ravel())\n",
    "res_list = []\n",
    "# Iterate over each model\n",
    "for model in ['bbc_r', 'generic_gpt35_r', 'generic_gpt4_r', 'silicon_gpt35_r', 'silicon_gpt4_r']:\n",
    "    # Expand the data for each model\n",
    "    for v1 in unique_values:\n",
    "        for v2 in unique_values:\n",
    "            r_value = combined_intercorrs_df.loc[(combined_intercorrs_df['var1'] == v1) & (combined_intercorrs_df['var2'] == v2), model]\n",
    "            if r_value.empty:\n",
    "                r_value = combined_intercorrs_df.loc[(combined_intercorrs_df['var1'] == v2) & (combined_intercorrs_df['var2'] == v1), model]\n",
    "            if r_value.empty:\n",
    "                r = pd.NA\n",
    "            else:\n",
    "                r = r_value.iloc[0]\n",
    "            # :-2 is to remove the \"_r\" suffix\n",
    "            res_list.append({'var1': v1, 'var2': v2, 'model': model[:-2], 'r': r})\n",
    "\n",
    "intercorrs_for_R = pd.DataFrame(res_list)\n",
    "intercorrs_for_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercorrs_for_R.to_csv(os.path.join(\"data\", \"data_for_R\", \"intercorrs.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is run in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"bbc_data\")):\n",
    "    # no part of this is shared; only the loadings will be shared (see R_codebook.Rmd)\n",
    "    pass\n",
    "else:\n",
    "    bbc_df[[\"uid\", \"item_index\", \"dimension\", \"response_reversed\"]].to_csv(os.path.join(\"data\", \"bbc_data\", \"bbc_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_gpt35_df[[\"uid\", \"scale\", \"item_index\", \"dimension\", \"response_reversed\"]].to_csv(os.path.join(\"data\", \"data_for_R\", \"generic_gpt35_df.csv\"), index=False)\n",
    "generic_gpt4_df[[\"uid\", \"scale\", \"item_index\", \"dimension\", \"response_reversed\"]].to_csv(os.path.join(\"data\", \"data_for_R\", \"generic_gpt4_df.csv\"), index=False)\n",
    "silicon_gpt35_df[[\"uid\", \"scale\", \"item_index\", \"dimension\", \"response_reversed\"]].to_csv(os.path.join(\"data\", \"data_for_R\", \"silicon_gpt35_df.csv\"), index=False)\n",
    "silicon_gpt4_df[[\"uid\", \"scale\", \"item_index\", \"dimension\", \"response_reversed\"]].to_csv(os.path.join(\"data\", \"data_for_R\", \"silicon_gpt4_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item analysis (frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to get the relative frequencies of individual-level responses on the BFI-44 items\n",
    "def get_rel_freq(df, id_col=\"uid\", colname_prefix='', group_cols=[\"dimension\", \"response_reversed\"]):\n",
    "    df = df[[id_col] + group_cols]\n",
    "    \n",
    "    df_grouped = df.groupby(group_cols).count()\n",
    "    df_grouped[f'{colname_prefix+\"_\" if colname_prefix!=\"\" else \"\"}total_count'] = df_grouped[[id_col]].groupby(level=0)[id_col].transform('sum')\n",
    "    df_grouped[f'{colname_prefix+\"_\" if colname_prefix!=\"\" else \"\"}relative_frequency'] = df_grouped[id_col] / df_grouped[f'{colname_prefix+\"_\" if colname_prefix!=\"\" else \"\"}total_count']\n",
    "    df_grouped = df_grouped.drop(columns=[id_col]).reset_index()\n",
    "\n",
    "    # this ensures that the dataframe contains all possible combinations of dimension and response\n",
    "    # e.g. if there are no responses of \"1\" for the dimension \"Extraversion\", the dataframe will still contain a row for that combination with a count of 0\n",
    "    # this is important for the visualization\n",
    "    all_dimensions = df_grouped[group_cols[0]].unique()\n",
    "    all_responses = df_grouped[group_cols[1]].unique()\n",
    "    all_combinations = pd.MultiIndex.from_product([all_dimensions, all_responses], names=group_cols).to_frame(index=False)\n",
    "    \n",
    "    df_grouped = pd.merge(all_combinations, df_grouped, on=group_cols, how='left').fillna(0, inplace=False).sort_values(group_cols)\n",
    "    \n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"bbc_data\")):\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_bfi_item_frequencies.pickle\"), \"rb\") as f:\n",
    "        bbc_bfi_item_frequencies = pickle.load(f)\n",
    "else:\n",
    "    bbc_bfi_item_frequencies = get_rel_freq(bbc_df[[\"uid\", \"dimension\", \"response_reversed\"]], colname_prefix=\"bbc\")\n",
    "\n",
    "    with open(os.path.join(\"data\", \"bbc_data_for_sharing\", \"bbc_bfi_item_frequencies.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(bbc_bfi_item_frequencies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>response_reversed</th>\n",
       "      <th>bbc_total_count</th>\n",
       "      <th>bbc_relative_frequency</th>\n",
       "      <th>generic_gpt35_total_count</th>\n",
       "      <th>generic_gpt35_relative_frequency</th>\n",
       "      <th>generic_gpt4_total_count</th>\n",
       "      <th>generic_gpt4_relative_frequency</th>\n",
       "      <th>silicon_gpt35_total_count</th>\n",
       "      <th>silicon_gpt35_relative_frequency</th>\n",
       "      <th>silicon_gpt4_total_count</th>\n",
       "      <th>silicon_gpt4_relative_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>1349</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>1311</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8996.0</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.148625</td>\n",
       "      <td>1349</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>1311</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.157875</td>\n",
       "      <td>1349</td>\n",
       "      <td>0.667161</td>\n",
       "      <td>1311</td>\n",
       "      <td>0.244851</td>\n",
       "      <td>8995.0</td>\n",
       "      <td>0.155642</td>\n",
       "      <td>8996.0</td>\n",
       "      <td>0.263450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.368632</td>\n",
       "      <td>1349</td>\n",
       "      <td>0.235730</td>\n",
       "      <td>1311</td>\n",
       "      <td>0.404272</td>\n",
       "      <td>8995.0</td>\n",
       "      <td>0.629016</td>\n",
       "      <td>8996.0</td>\n",
       "      <td>0.581258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.287898</td>\n",
       "      <td>1349</td>\n",
       "      <td>0.065234</td>\n",
       "      <td>1311</td>\n",
       "      <td>0.290618</td>\n",
       "      <td>8995.0</td>\n",
       "      <td>0.215342</td>\n",
       "      <td>8996.0</td>\n",
       "      <td>0.154624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.053783</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>1335</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8997.0</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.168023</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.054937</td>\n",
       "      <td>1335</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>8988.0</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>8997.0</td>\n",
       "      <td>0.003446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.173533</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.542687</td>\n",
       "      <td>1335</td>\n",
       "      <td>0.238951</td>\n",
       "      <td>8988.0</td>\n",
       "      <td>0.199377</td>\n",
       "      <td>8997.0</td>\n",
       "      <td>0.255085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.333599</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.273942</td>\n",
       "      <td>1335</td>\n",
       "      <td>0.403745</td>\n",
       "      <td>8988.0</td>\n",
       "      <td>0.558634</td>\n",
       "      <td>8997.0</td>\n",
       "      <td>0.508614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2270133</td>\n",
       "      <td>0.271063</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.121752</td>\n",
       "      <td>1335</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>8988.0</td>\n",
       "      <td>0.238874</td>\n",
       "      <td>8997.0</td>\n",
       "      <td>0.232189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.084236</td>\n",
       "      <td>1199</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7996.0</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.230832</td>\n",
       "      <td>1199</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>0.113267</td>\n",
       "      <td>7996.0</td>\n",
       "      <td>0.097299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.221158</td>\n",
       "      <td>1199</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.365401</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>7996.0</td>\n",
       "      <td>0.452101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.301503</td>\n",
       "      <td>1199</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>0.567209</td>\n",
       "      <td>7996.0</td>\n",
       "      <td>0.446598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Extraversion</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.162271</td>\n",
       "      <td>1199</td>\n",
       "      <td>0.028357</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.147679</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>7996.0</td>\n",
       "      <td>0.003627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.140102</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>1171</td>\n",
       "      <td>0.095645</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>7789.0</td>\n",
       "      <td>0.023110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.245275</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.188805</td>\n",
       "      <td>1171</td>\n",
       "      <td>0.368915</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>0.412863</td>\n",
       "      <td>7789.0</td>\n",
       "      <td>0.373219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.200597</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>1171</td>\n",
       "      <td>0.397096</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>0.499874</td>\n",
       "      <td>7789.0</td>\n",
       "      <td>0.552189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.294369</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>1171</td>\n",
       "      <td>0.120410</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>0.055864</td>\n",
       "      <td>7789.0</td>\n",
       "      <td>0.050071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017896</td>\n",
       "      <td>0.119657</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.010860</td>\n",
       "      <td>1171</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7789.0</td>\n",
       "      <td>0.001412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Openness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2522370</td>\n",
       "      <td>0.045663</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>1486</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Openness</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2522370</td>\n",
       "      <td>0.126470</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.044696</td>\n",
       "      <td>1486</td>\n",
       "      <td>0.077389</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>0.028314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Openness</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2522370</td>\n",
       "      <td>0.195958</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.647765</td>\n",
       "      <td>1486</td>\n",
       "      <td>0.281965</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.302111</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>0.382991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Openness</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2522370</td>\n",
       "      <td>0.351287</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.206137</td>\n",
       "      <td>1486</td>\n",
       "      <td>0.426649</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.666967</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>0.554877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Openness</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2522370</td>\n",
       "      <td>0.280621</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.082722</td>\n",
       "      <td>1486</td>\n",
       "      <td>0.204576</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>0.021715</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>0.033117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dimension  response_reversed  bbc_total_count  \\\n",
       "0       Agreeableness                1.0          2270133   \n",
       "1       Agreeableness                2.0          2270133   \n",
       "2       Agreeableness                3.0          2270133   \n",
       "3       Agreeableness                4.0          2270133   \n",
       "4       Agreeableness                5.0          2270133   \n",
       "5   Conscientiousness                1.0          2270133   \n",
       "6   Conscientiousness                2.0          2270133   \n",
       "7   Conscientiousness                3.0          2270133   \n",
       "8   Conscientiousness                4.0          2270133   \n",
       "9   Conscientiousness                5.0          2270133   \n",
       "10       Extraversion                1.0          2017896   \n",
       "11       Extraversion                2.0          2017896   \n",
       "12       Extraversion                3.0          2017896   \n",
       "13       Extraversion                4.0          2017896   \n",
       "14       Extraversion                5.0          2017896   \n",
       "15        Neuroticism                1.0          2017896   \n",
       "16        Neuroticism                2.0          2017896   \n",
       "17        Neuroticism                3.0          2017896   \n",
       "18        Neuroticism                4.0          2017896   \n",
       "19        Neuroticism                5.0          2017896   \n",
       "20           Openness                1.0          2522370   \n",
       "21           Openness                2.0          2522370   \n",
       "22           Openness                3.0          2522370   \n",
       "23           Openness                4.0          2522370   \n",
       "24           Openness                5.0          2522370   \n",
       "\n",
       "    bbc_relative_frequency  generic_gpt35_total_count  \\\n",
       "0                 0.036970                       1349   \n",
       "1                 0.148625                       1349   \n",
       "2                 0.157875                       1349   \n",
       "3                 0.368632                       1349   \n",
       "4                 0.287898                       1349   \n",
       "5                 0.053783                       1347   \n",
       "6                 0.168023                       1347   \n",
       "7                 0.173533                       1347   \n",
       "8                 0.333599                       1347   \n",
       "9                 0.271063                       1347   \n",
       "10                0.084236                       1199   \n",
       "11                0.230832                       1199   \n",
       "12                0.221158                       1199   \n",
       "13                0.301503                       1199   \n",
       "14                0.162271                       1199   \n",
       "15                0.140102                       1197   \n",
       "16                0.245275                       1197   \n",
       "17                0.200597                       1197   \n",
       "18                0.294369                       1197   \n",
       "19                0.119657                       1197   \n",
       "20                0.045663                       1499   \n",
       "21                0.126470                       1499   \n",
       "22                0.195958                       1499   \n",
       "23                0.351287                       1499   \n",
       "24                0.280621                       1499   \n",
       "\n",
       "    generic_gpt35_relative_frequency  generic_gpt4_total_count  \\\n",
       "0                           0.006672                      1311   \n",
       "1                           0.025204                      1311   \n",
       "2                           0.667161                      1311   \n",
       "3                           0.235730                      1311   \n",
       "4                           0.065234                      1311   \n",
       "5                           0.006682                      1335   \n",
       "6                           0.054937                      1335   \n",
       "7                           0.542687                      1335   \n",
       "8                           0.273942                      1335   \n",
       "9                           0.121752                      1335   \n",
       "10                          0.013344                      1185   \n",
       "11                          0.083403                      1185   \n",
       "12                          0.737281                      1185   \n",
       "13                          0.137615                      1185   \n",
       "14                          0.028357                      1185   \n",
       "15                          0.028404                      1171   \n",
       "16                          0.188805                      1171   \n",
       "17                          0.721805                      1171   \n",
       "18                          0.050125                      1171   \n",
       "19                          0.010860                      1171   \n",
       "20                          0.018679                      1486   \n",
       "21                          0.044696                      1486   \n",
       "22                          0.647765                      1486   \n",
       "23                          0.206137                      1486   \n",
       "24                          0.082722                      1486   \n",
       "\n",
       "    generic_gpt4_relative_frequency  silicon_gpt35_total_count  \\\n",
       "0                          0.026697                        0.0   \n",
       "1                          0.033562                        0.0   \n",
       "2                          0.244851                     8995.0   \n",
       "3                          0.404272                     8995.0   \n",
       "4                          0.290618                     8995.0   \n",
       "5                          0.006742                        0.0   \n",
       "6                          0.047191                     8988.0   \n",
       "7                          0.238951                     8988.0   \n",
       "8                          0.403745                     8988.0   \n",
       "9                          0.303371                     8988.0   \n",
       "10                         0.027004                        0.0   \n",
       "11                         0.092827                     7990.0   \n",
       "12                         0.365401                     7990.0   \n",
       "13                         0.367089                     7990.0   \n",
       "14                         0.147679                     7990.0   \n",
       "15                         0.095645                     7930.0   \n",
       "16                         0.368915                     7930.0   \n",
       "17                         0.397096                     7930.0   \n",
       "18                         0.120410                     7930.0   \n",
       "19                         0.017933                        0.0   \n",
       "20                         0.009421                     9993.0   \n",
       "21                         0.077389                     9993.0   \n",
       "22                         0.281965                     9993.0   \n",
       "23                         0.426649                     9993.0   \n",
       "24                         0.204576                     9993.0   \n",
       "\n",
       "    silicon_gpt35_relative_frequency  silicon_gpt4_total_count  \\\n",
       "0                           0.000000                    8996.0   \n",
       "1                           0.000000                       0.0   \n",
       "2                           0.155642                    8996.0   \n",
       "3                           0.629016                    8996.0   \n",
       "4                           0.215342                    8996.0   \n",
       "5                           0.000000                    8997.0   \n",
       "6                           0.003115                    8997.0   \n",
       "7                           0.199377                    8997.0   \n",
       "8                           0.558634                    8997.0   \n",
       "9                           0.238874                    8997.0   \n",
       "10                          0.000000                    7996.0   \n",
       "11                          0.113267                    7996.0   \n",
       "12                          0.319149                    7996.0   \n",
       "13                          0.567209                    7996.0   \n",
       "14                          0.000375                    7996.0   \n",
       "15                          0.031400                    7789.0   \n",
       "16                          0.412863                    7789.0   \n",
       "17                          0.499874                    7789.0   \n",
       "18                          0.055864                    7789.0   \n",
       "19                          0.000000                    7789.0   \n",
       "20                          0.000901                    9995.0   \n",
       "21                          0.008306                    9995.0   \n",
       "22                          0.302111                    9995.0   \n",
       "23                          0.666967                    9995.0   \n",
       "24                          0.021715                    9995.0   \n",
       "\n",
       "    silicon_gpt4_relative_frequency  \n",
       "0                          0.000667  \n",
       "1                          0.000000  \n",
       "2                          0.263450  \n",
       "3                          0.581258  \n",
       "4                          0.154624  \n",
       "5                          0.000667  \n",
       "6                          0.003446  \n",
       "7                          0.255085  \n",
       "8                          0.508614  \n",
       "9                          0.232189  \n",
       "10                         0.000375  \n",
       "11                         0.097299  \n",
       "12                         0.452101  \n",
       "13                         0.446598  \n",
       "14                         0.003627  \n",
       "15                         0.023110  \n",
       "16                         0.373219  \n",
       "17                         0.552189  \n",
       "18                         0.050071  \n",
       "19                         0.001412  \n",
       "20                         0.000700  \n",
       "21                         0.028314  \n",
       "22                         0.382991  \n",
       "23                         0.554877  \n",
       "24                         0.033117  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_gpt35_bfi_item_frequencies = get_rel_freq(generic_gpt35_df.query(\"scale=='BFI'\")[[\"uid\", \"dimension\", \"response_reversed\"]], colname_prefix=\"generic_gpt35\")\n",
    "generic_gpt4_bfi_item_frequencies = get_rel_freq(generic_gpt4_df.query(\"scale=='BFI'\")[[\"uid\", \"dimension\", \"response_reversed\"]], colname_prefix=\"generic_gpt4\")\n",
    "silicon_gpt35_bfi_item_frequencies = get_rel_freq(silicon_gpt35_df.query(\"scale=='BFI'\")[[\"uid\", \"dimension\", \"response_reversed\"]], colname_prefix=\"silicon_gpt35\")\n",
    "silicon_gpt4_bfi_item_frequencies = get_rel_freq(silicon_gpt4_df.query(\"scale=='BFI'\")[[\"uid\", \"dimension\", \"response_reversed\"]], colname_prefix=\"silicon_gpt4\")\n",
    "\n",
    "# use reduce to combine the item_frequency dataframes without renaming columns\n",
    "tmp = [bbc_bfi_item_frequencies, #sample_bbc_bfi_item_frequencies, \n",
    "        generic_gpt35_bfi_item_frequencies, generic_gpt4_bfi_item_frequencies, \n",
    "        silicon_gpt35_bfi_item_frequencies, silicon_gpt4_bfi_item_frequencies]\n",
    "combined_bfi_item_frequencies = reduce(lambda left, right: pd.merge(left, right, on=[\"dimension\", \"response_reversed\"], how='inner'), tmp)\n",
    "combined_bfi_item_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined_bfi_item_frequencies\n",
    "    .melt(id_vars=[\"dimension\", \"response_reversed\"], \n",
    "            value_vars=[e for e in combined_bfi_item_frequencies.columns if e.endswith(\"relative_frequency\")], \n",
    "            var_name=\"model\", value_name=\"relative_frequency\")\n",
    "    .to_csv(os.path.join(\"data\", \"data_for_R\", \"combined_bfi_item_frequencies.csv\"), index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess the data frames\n",
    "def get_bias_df(summary_scores_df, prefix):\n",
    "    # reusing the wide function from the validity section\n",
    "    summary_scores_df_wide = get_summary_scores_df_wide(summary_scores_df)\n",
    "    # Filter columns starting with \"BFI_\" and include \"uid\"\n",
    "    filtered_df = summary_scores_df_wide.filter(regex='^BFI_|^uid$')\n",
    "    # Rename columns using a dictionary comprehension\n",
    "    rename_map = {col: f\"{prefix}_{col.split('_')[-1]}\" for col in filtered_df.columns if col.startswith('BFI')}\n",
    "    return filtered_df.rename(columns=rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>scale</th>\n",
       "      <th>uid</th>\n",
       "      <th>BFI_Agreeableness</th>\n",
       "      <th>BFI_Conscientiousness</th>\n",
       "      <th>BFI_Extraversion</th>\n",
       "      <th>BFI_Neuroticism</th>\n",
       "      <th>BFI_Openness</th>\n",
       "      <th>gpt35_Agreeableness</th>\n",
       "      <th>gpt35_Conscientiousness</th>\n",
       "      <th>gpt35_Extraversion</th>\n",
       "      <th>gpt35_Neuroticism</th>\n",
       "      <th>...</th>\n",
       "      <th>bias_gpt35_Neuroticism</th>\n",
       "      <th>bias_gpt4_Neuroticism</th>\n",
       "      <th>bias_gpt35_Conscientiousness</th>\n",
       "      <th>bias_gpt4_Conscientiousness</th>\n",
       "      <th>bias_gpt35_Extraversion</th>\n",
       "      <th>bias_gpt4_Extraversion</th>\n",
       "      <th>bias_gpt35_Openness</th>\n",
       "      <th>bias_gpt4_Openness</th>\n",
       "      <th>bias_gpt35_avg</th>\n",
       "      <th>bias_gpt4_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00370bf8406c470e3d4f5d428ddb2acc1a43476c</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.875</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>3.625</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840556</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00971fc6fda4283c98bc4c1d8135972c1229a07e</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>1.875</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>3.375</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.989603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00be86e5dc52a407da67ffb5395ad6ea9381d703</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2.500</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.231667</td>\n",
       "      <td>0.293175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c99d987d8808e711c8108a9889384d01c26db3</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.250</td>\n",
       "      <td>4.375</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>1.517857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.126905</td>\n",
       "      <td>0.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0104a608dbf05a1471ae8a5c701b3177366d0180</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.500</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>3.375</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816905</td>\n",
       "      <td>0.838889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>fe96cb89a11af0a1706aac961f87044d6ede4cd9</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>4.375</td>\n",
       "      <td>2.375</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.473889</td>\n",
       "      <td>0.531111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>fedd5c55c53db2c554d986adf4781f36963560b8</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>3.750</td>\n",
       "      <td>2.375</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.152302</td>\n",
       "      <td>0.142222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ff4aa0569bce2c0c40ce7abeb5f0f65b67ef8ffe</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>2.500</td>\n",
       "      <td>3.750</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.625</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.916111</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ff6c27789e3033e7b6b44a8fd4f9370693642867</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.250</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.426111</td>\n",
       "      <td>0.294365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ff78226bd24bf7a7b816a12c7f598e324a8f1a0e</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.625</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.857222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scale                                       uid  BFI_Agreeableness  \\\n",
       "0      00370bf8406c470e3d4f5d428ddb2acc1a43476c           3.333333   \n",
       "1      00971fc6fda4283c98bc4c1d8135972c1229a07e           4.000000   \n",
       "2      00be86e5dc52a407da67ffb5395ad6ea9381d703           4.111111   \n",
       "3      00c99d987d8808e711c8108a9889384d01c26db3           2.666667   \n",
       "4      0104a608dbf05a1471ae8a5c701b3177366d0180           3.222222   \n",
       "..                                          ...                ...   \n",
       "995    fe96cb89a11af0a1706aac961f87044d6ede4cd9           4.333333   \n",
       "996    fedd5c55c53db2c554d986adf4781f36963560b8           4.222222   \n",
       "997    ff4aa0569bce2c0c40ce7abeb5f0f65b67ef8ffe           2.777778   \n",
       "998    ff6c27789e3033e7b6b44a8fd4f9370693642867           3.666667   \n",
       "999    ff78226bd24bf7a7b816a12c7f598e324a8f1a0e           3.111111   \n",
       "\n",
       "scale  BFI_Conscientiousness  BFI_Extraversion  BFI_Neuroticism  BFI_Openness  \\\n",
       "0                   2.000000             3.875            3.125           3.4   \n",
       "1                   3.222222             1.875            3.500           2.5   \n",
       "2                   4.777778             2.875            2.500           3.6   \n",
       "3                   2.666667             1.250            4.375           4.3   \n",
       "4                   3.333333             3.000            4.500           2.9   \n",
       "..                       ...               ...              ...           ...   \n",
       "995                 4.222222             4.375            2.375           4.7   \n",
       "996                 4.555556             3.750            2.375           3.5   \n",
       "997                 3.888889             2.500            3.750           3.3   \n",
       "998                 4.000000             3.625            3.625           3.8   \n",
       "999                 2.444444             2.250            2.625           4.4   \n",
       "\n",
       "scale  gpt35_Agreeableness  gpt35_Conscientiousness  gpt35_Extraversion  \\\n",
       "0                 3.888889                 4.222222               3.625   \n",
       "1                 4.111111                 4.222222               3.375   \n",
       "2                 4.111111                 4.444444               3.500   \n",
       "3                 3.555556                 3.444444               3.000   \n",
       "4                 4.111111                 4.111111               3.375   \n",
       "..                     ...                      ...                 ...   \n",
       "995               4.000000                 4.111111               3.500   \n",
       "996               4.222222                 4.333333               3.500   \n",
       "997               3.888889                 4.333333               3.625   \n",
       "998               4.222222                 4.000000               3.250   \n",
       "999               4.111111                 4.111111               3.500   \n",
       "\n",
       "scale  gpt35_Neuroticism  ...  bias_gpt35_Neuroticism  bias_gpt4_Neuroticism  \\\n",
       "0               2.250000  ...                0.875000               0.500000   \n",
       "1               2.333333  ...                1.166667               0.928571   \n",
       "2               2.500000  ...                0.000000               0.071429   \n",
       "3               2.857143  ...                1.517857               0.875000   \n",
       "4               2.857143  ...                1.642857               1.750000   \n",
       "..                   ...  ...                     ...                    ...   \n",
       "995             2.625000  ...                0.250000               0.250000   \n",
       "996             2.285714  ...                0.089286               0.250000   \n",
       "997             2.250000  ...                1.500000               1.125000   \n",
       "998             2.625000  ...                1.000000               0.910714   \n",
       "999             2.250000  ...                0.375000               0.250000   \n",
       "\n",
       "scale  bias_gpt35_Conscientiousness  bias_gpt4_Conscientiousness  \\\n",
       "0                          2.222222                     2.333333   \n",
       "1                          1.000000                     1.111111   \n",
       "2                          0.333333                     0.444444   \n",
       "3                          0.777778                     0.666667   \n",
       "4                          0.777778                     0.444444   \n",
       "..                              ...                          ...   \n",
       "995                        0.111111                     0.222222   \n",
       "996                        0.222222                     0.000000   \n",
       "997                        0.444444                     0.777778   \n",
       "998                        0.000000                     0.000000   \n",
       "999                        1.666667                     1.444444   \n",
       "\n",
       "scale  bias_gpt35_Extraversion  bias_gpt4_Extraversion  bias_gpt35_Openness  \\\n",
       "0                        0.250                   0.375             0.300000   \n",
       "1                        1.500                   1.375             1.388889   \n",
       "2                        0.625                   0.750             0.200000   \n",
       "3                        1.750                   1.625             0.700000   \n",
       "4                        0.375                   0.500             0.400000   \n",
       "..                         ...                     ...                  ...   \n",
       "995                      0.875                   0.750             0.800000   \n",
       "996                      0.250                   0.250             0.200000   \n",
       "997                      1.125                   1.125             0.400000   \n",
       "998                      0.375                   0.250             0.200000   \n",
       "999                      1.250                   1.125             0.700000   \n",
       "\n",
       "scale  bias_gpt4_Openness  bias_gpt35_avg  bias_gpt4_avg  \n",
       "0                     0.0        0.840556       0.708333  \n",
       "1                     1.2        1.033333       0.989603  \n",
       "2                     0.2        0.231667       0.293175  \n",
       "3                     0.8        1.126905       0.926667  \n",
       "4                     0.5        0.816905       0.838889  \n",
       "..                    ...             ...            ...  \n",
       "995                   1.1        0.473889       0.531111  \n",
       "996                   0.1        0.152302       0.142222  \n",
       "997                   0.5        0.916111       0.950000  \n",
       "998                   0.2        0.426111       0.294365  \n",
       "999                   0.8        0.998333       0.857222  \n",
       "\n",
       "[1000 rows x 28 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_summary_scores_df_wide = get_summary_scores_df_wide(bbc_summary_scores_df)\n",
    "\n",
    "silicon_gpt35_bias_df = get_bias_df(silicon_gpt35_summary_scores_df, 'gpt35')\n",
    "silicon_gpt4_bias_df = get_bias_df(silicon_gpt4_summary_scores_df, 'gpt4')\n",
    "\n",
    "bias_df = bbc_summary_scores_df_wide.merge(silicon_gpt35_bias_df, on='uid', how='inner').merge(silicon_gpt4_bias_df, on='uid', how='inner')\n",
    "\n",
    "# Traits for iteration\n",
    "traits = ['Agreeableness', 'Neuroticism', 'Conscientiousness', 'Extraversion', 'Openness']\n",
    "\n",
    "# Calculate biases for GPT3.5 and GPT4\n",
    "for trait in traits:\n",
    "    for version in ['gpt35', 'gpt4']:\n",
    "        bias_df[f'bias_{version}_{trait}'] = np.abs(bias_df[f'{version}_{trait}'] - bias_df[f\"BFI_{trait}\"])\n",
    "\n",
    "# Calculate average biases\n",
    "for version in ['gpt35', 'gpt4']:\n",
    "    bias_df[f'bias_{version}_avg'] = bias_df[[f'bias_{version}_{trait}' for trait in traits]].mean(axis=1)\n",
    "\n",
    "bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias for GPT-3.5: 0.63 (SD: 0.25)\n",
      "Bias for GPT-4: 0.62 (SD: 0.24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bias for GPT-3.5: {np.round(np.mean(bias_df['bias_gpt35_avg']), 2)} (SD: {np.round(np.std(bias_df['bias_gpt35_avg']), 2)})\")\n",
    "print(f\"Bias for GPT-4: {np.round(np.mean(bias_df['bias_gpt4_avg']), 2)} (SD: {np.round(np.std(bias_df['bias_gpt4_avg']), 2)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test results: t=1.38, p-value=0.169; Cohen's d=0.06\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = ttest_ind_from_stats(mean1=np.mean(bias_df['bias_gpt35_avg']), std1=np.std(bias_df['bias_gpt35_avg']), nobs1=1000,\n",
    "                    mean2=np.mean(bias_df['bias_gpt4_avg']), std2=np.std(bias_df['bias_gpt4_avg']), nobs2=1000,\n",
    "                    equal_var=True)  # assuming equal variances\n",
    "cohen_d = pg.compute_effsize(bias_df['bias_gpt35_avg'], bias_df['bias_gpt4_avg'], eftype='cohen')\n",
    "print(f\"t-test results: t={np.round(t_stat, 2)}, p-value={np.round(p_val, 3)}; Cohen's d={np.round(cohen_d, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = bias_df.melt(id_vars=[\"uid\"], value_vars=[e for e in bias_df.columns if e.startswith(\"bias_\") and not e.endswith(\"avg\")], var_name=\"tmp\", value_name=\"bias\")\n",
    "tmp[['x', 'model', 'trait']] = tmp['tmp'].str.split('_', expand=True)\n",
    "\n",
    "tmp[[\"uid\", \"model\", \"trait\", \"bias\"]].to_csv(os.path.join(\"data\", \"data_for_R\", \"bias_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>BFI_Agreeableness</th>\n",
       "      <th>BFI_Conscientiousness</th>\n",
       "      <th>BFI_Extraversion</th>\n",
       "      <th>BFI_Neuroticism</th>\n",
       "      <th>BFI_Openness</th>\n",
       "      <th>bias_gpt35_avg</th>\n",
       "      <th>bias_gpt4_avg</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>m_schl</th>\n",
       "      <th>f_schl</th>\n",
       "      <th>n_sib</th>\n",
       "      <th>sex</th>\n",
       "      <th>st_pub</th>\n",
       "      <th>occ_sta</th>\n",
       "      <th>occ_cat</th>\n",
       "      <th>income</th>\n",
       "      <th>rstat_1</th>\n",
       "      <th>chldrn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias_gpt35_avg</td>\n",
       "      <td>-0.336785</td>\n",
       "      <td>-0.369423</td>\n",
       "      <td>-0.291651</td>\n",
       "      <td>0.387875</td>\n",
       "      <td>-0.136477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916592</td>\n",
       "      <td>0.024693</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>-0.018809</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.104279</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.022803</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.028359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bias_gpt4_avg</td>\n",
       "      <td>-0.213615</td>\n",
       "      <td>-0.321367</td>\n",
       "      <td>-0.178874</td>\n",
       "      <td>0.309813</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>0.916592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014135</td>\n",
       "      <td>0.015438</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>-0.038325</td>\n",
       "      <td>-0.005128</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>0.054913</td>\n",
       "      <td>-0.006492</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>-0.000871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  BFI_Agreeableness  BFI_Conscientiousness  BFI_Extraversion  \\\n",
       "0  bias_gpt35_avg          -0.336785              -0.369423         -0.291651   \n",
       "1   bias_gpt4_avg          -0.213615              -0.321367         -0.178874   \n",
       "\n",
       "   BFI_Neuroticism  BFI_Openness  bias_gpt35_avg  bias_gpt4_avg       age  \\\n",
       "0         0.387875     -0.136477        1.000000       0.916592  0.024693   \n",
       "1         0.309813     -0.038655        0.916592       1.000000 -0.014135   \n",
       "\n",
       "     ethnic    m_schl    f_schl     n_sib       sex    st_pub   occ_sta  \\\n",
       "0  0.017889  0.003470  0.006160 -0.018809  0.004385  0.040039  0.104279   \n",
       "1  0.015438  0.018758  0.033611 -0.038325 -0.005128  0.037652  0.054913   \n",
       "\n",
       "    occ_cat    income   rstat_1    chldrn  \n",
       "0 -0.009396  0.022803  0.013411  0.028359  \n",
       "1 -0.006492  0.046243  0.014393 -0.000871  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_corrs_df = pd.merge(bias_df[[\"uid\"] + [e for e in bias_df.columns if e.startswith(\"BFI_\") or e.endswith(\"_avg\")]],\n",
    "        bbc_silicon_samples_df.drop(columns=[\"country_name\", \"country\"]), \n",
    "        on=['uid'], how='left')\n",
    "\n",
    "bias_corrs_df = bias_corrs_df.select_dtypes(include=np.number).corr().loc[['bias_gpt35_avg', 'bias_gpt4_avg'],].reset_index(names=\"model\")\n",
    "bias_corrs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data export for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bias_corrs_df\n",
    "    .melt(id_vars=[\"model\"], var_name=\"var\", value_name=\"r\")\n",
    "    .query(\"var!='bias_gpt35_avg' and var!='bias_gpt4_avg'\")\n",
    "    .reset_index(drop=True)\n",
    "    .to_csv(os.path.join(\"data\", \"data_for_R\", \"bias_corrs_df.csv\"), index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary: Analysis of the first token of the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_token_is_digit</th>\n",
       "      <th>response_reversed</th>\n",
       "      <th>generic_gpt35_total_count</th>\n",
       "      <th>generic_gpt35_relative_frequency</th>\n",
       "      <th>generic_gpt4_total_count</th>\n",
       "      <th>generic_gpt4_relative_frequency</th>\n",
       "      <th>silicon_gpt35_total_count</th>\n",
       "      <th>silicon_gpt35_relative_frequency</th>\n",
       "      <th>silicon_gpt4_total_count</th>\n",
       "      <th>silicon_gpt4_relative_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6022</td>\n",
       "      <td>0.044171</td>\n",
       "      <td>14688</td>\n",
       "      <td>0.112064</td>\n",
       "      <td>85658.0</td>\n",
       "      <td>0.031719</td>\n",
       "      <td>84581</td>\n",
       "      <td>0.084523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6022</td>\n",
       "      <td>0.177682</td>\n",
       "      <td>14688</td>\n",
       "      <td>0.182734</td>\n",
       "      <td>85658.0</td>\n",
       "      <td>0.159822</td>\n",
       "      <td>84581</td>\n",
       "      <td>0.183221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6022</td>\n",
       "      <td>0.183826</td>\n",
       "      <td>14688</td>\n",
       "      <td>0.291326</td>\n",
       "      <td>85658.0</td>\n",
       "      <td>0.215718</td>\n",
       "      <td>84581</td>\n",
       "      <td>0.361606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6022</td>\n",
       "      <td>0.531717</td>\n",
       "      <td>14688</td>\n",
       "      <td>0.291803</td>\n",
       "      <td>85658.0</td>\n",
       "      <td>0.536611</td>\n",
       "      <td>84581</td>\n",
       "      <td>0.323359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6022</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>14688</td>\n",
       "      <td>0.122072</td>\n",
       "      <td>85658.0</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>84581</td>\n",
       "      <td>0.047292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9542</td>\n",
       "      <td>0.066338</td>\n",
       "      <td>440</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>18226.0</td>\n",
       "      <td>0.204269</td>\n",
       "      <td>18267</td>\n",
       "      <td>0.045656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9542</td>\n",
       "      <td>0.075875</td>\n",
       "      <td>440</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>18226.0</td>\n",
       "      <td>0.102601</td>\n",
       "      <td>18267</td>\n",
       "      <td>0.068320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9542</td>\n",
       "      <td>0.709495</td>\n",
       "      <td>440</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>18226.0</td>\n",
       "      <td>0.684462</td>\n",
       "      <td>18267</td>\n",
       "      <td>0.294794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9542</td>\n",
       "      <td>0.125236</td>\n",
       "      <td>440</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>18226.0</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>18267</td>\n",
       "      <td>0.581759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9542</td>\n",
       "      <td>0.023056</td>\n",
       "      <td>440</td>\n",
       "      <td>0.059091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18267</td>\n",
       "      <td>0.009471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_token_is_digit  response_reversed  generic_gpt35_total_count  \\\n",
       "0                 False                1.0                       6022   \n",
       "1                 False                2.0                       6022   \n",
       "2                 False                3.0                       6022   \n",
       "3                 False                4.0                       6022   \n",
       "4                 False                5.0                       6022   \n",
       "5                  True                1.0                       9542   \n",
       "6                  True                2.0                       9542   \n",
       "7                  True                3.0                       9542   \n",
       "8                  True                4.0                       9542   \n",
       "9                  True                5.0                       9542   \n",
       "\n",
       "   generic_gpt35_relative_frequency  generic_gpt4_total_count  \\\n",
       "0                          0.044171                     14688   \n",
       "1                          0.177682                     14688   \n",
       "2                          0.183826                     14688   \n",
       "3                          0.531717                     14688   \n",
       "4                          0.062604                     14688   \n",
       "5                          0.066338                       440   \n",
       "6                          0.075875                       440   \n",
       "7                          0.709495                       440   \n",
       "8                          0.125236                       440   \n",
       "9                          0.023056                       440   \n",
       "\n",
       "   generic_gpt4_relative_frequency  silicon_gpt35_total_count  \\\n",
       "0                         0.112064                    85658.0   \n",
       "1                         0.182734                    85658.0   \n",
       "2                         0.291326                    85658.0   \n",
       "3                         0.291803                    85658.0   \n",
       "4                         0.122072                    85658.0   \n",
       "5                         0.170455                    18226.0   \n",
       "6                         0.045455                    18226.0   \n",
       "7                         0.034091                    18226.0   \n",
       "8                         0.690909                    18226.0   \n",
       "9                         0.059091                        0.0   \n",
       "\n",
       "   silicon_gpt35_relative_frequency  silicon_gpt4_total_count  \\\n",
       "0                          0.031719                     84581   \n",
       "1                          0.159822                     84581   \n",
       "2                          0.215718                     84581   \n",
       "3                          0.536611                     84581   \n",
       "4                          0.056130                     84581   \n",
       "5                          0.204269                     18267   \n",
       "6                          0.102601                     18267   \n",
       "7                          0.684462                     18267   \n",
       "8                          0.008669                     18267   \n",
       "9                          0.000000                     18267   \n",
       "\n",
       "   silicon_gpt4_relative_frequency  \n",
       "0                         0.084523  \n",
       "1                         0.183221  \n",
       "2                         0.361606  \n",
       "3                         0.323359  \n",
       "4                         0.047292  \n",
       "5                         0.045656  \n",
       "6                         0.068320  \n",
       "7                         0.294794  \n",
       "8                         0.581759  \n",
       "9                         0.009471  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_gpt35_first_token_digit_item_frequencies = get_rel_freq(generic_gpt35_df, colname_prefix=\"generic_gpt35\", group_cols=[\"first_token_is_digit\", \"response_reversed\"])\n",
    "generic_gpt4_first_token_digit_item_frequencies = get_rel_freq(generic_gpt4_df, colname_prefix=\"generic_gpt4\", group_cols=[\"first_token_is_digit\", \"response_reversed\"])\n",
    "silicon_gpt35_first_token_digit_item_frequencies = get_rel_freq(silicon_gpt35_df, colname_prefix=\"silicon_gpt35\", group_cols=[\"first_token_is_digit\", \"response_reversed\"])\n",
    "silicon_gpt4_first_token_digit_item_frequencies = get_rel_freq(silicon_gpt4_df, colname_prefix=\"silicon_gpt4\", group_cols=[\"first_token_is_digit\", \"response_reversed\"])\n",
    "\n",
    "# use reduce to combine the item_frequency dataframes without renaming columns\n",
    "tmp = [generic_gpt35_first_token_digit_item_frequencies, generic_gpt4_first_token_digit_item_frequencies, \n",
    "        silicon_gpt35_first_token_digit_item_frequencies, silicon_gpt4_first_token_digit_item_frequencies]\n",
    "combined_first_token_digit_item_frequencies = reduce(lambda left, right: pd.merge(left, right, on=[\"first_token_is_digit\", \"response_reversed\"], how='inner'), tmp)\n",
    "combined_first_token_digit_item_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined_first_token_digit_item_frequencies\n",
    "    .melt(id_vars=[\"first_token_is_digit\", \"response_reversed\"], \n",
    "            value_vars=[e for e in combined_first_token_digit_item_frequencies.columns if e.endswith(\"relative_frequency\")], \n",
    "            var_name=\"model\", value_name=\"relative_frequency\")\n",
    "    .to_csv(os.path.join(\"data\", \"data_for_R\", \"combined_first_token_digit_item_frequencies.csv\"), index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
